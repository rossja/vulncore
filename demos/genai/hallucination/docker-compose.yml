services:
  llm-sqli-demo:
    build: .
    ports:
      - "8081:8000"
    volumes:
      - ollama-models:/root/.ollama  # Persist Ollama models between builds
    environment:
      - MODEL=tinyllama

volumes:
  ollama-models:  # Named volume for Ollama models 